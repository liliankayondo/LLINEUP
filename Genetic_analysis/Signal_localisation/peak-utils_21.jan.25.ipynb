{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd2b01cd-1407-40f9-91f6-0d7912e0b332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "import pandas as pd\n",
    "import malariagen_data\n",
    "import itertools\n",
    "import functools\n",
    "from pyprojroot import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fbb2e1c-46b0-4719-a399-fed1affcb713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define funcion for calculating/ modeling symetric peak\n",
    "\n",
    "def exponential_peak(x, center, amplitude, decay, baseline, floor, ceiling):\n",
    "    \"\"\"Symmetric exponential peak function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray\n",
    "        Independent variable.\n",
    "    center : int or float\n",
    "        The center of the peak.\n",
    "    amplitude : float\n",
    "        Amplitude parameter.\n",
    "    decay : float\n",
    "        Decay parameter.\n",
    "    baseline : float\n",
    "        Baseline parameter.\n",
    "    floor : float\n",
    "        Minimum value that the result can take.\n",
    "    ceiling : float\n",
    "        Maximum value that the result can take.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : ndarray\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # locate the index at which to split data into left and right flanks\n",
    "    ix_split = bisect_right(x, center)\n",
    "\n",
    "    # compute left flank\n",
    "    xl = center - x[:ix_split]\n",
    "    yl = baseline + amplitude * np.exp(-xl / decay)\n",
    "\n",
    "    # compute right flank\n",
    "    xr = x[ix_split:] - center\n",
    "    yr = baseline + amplitude * np.exp(-xr / decay)\n",
    "\n",
    "    # prepare output\n",
    "    y = np.concatenate([yl, yr])\n",
    "\n",
    "    # apply limits\n",
    "    y = y.clip(floor, ceiling)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "339c5785-4cac-4245-8292-4239988ccf8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##define fxn for modeling/ calculating asymetric peak \n",
    "def skewed_exponential_peak(x, center, amplitude, decay, skew, baseline, floor, ceiling):\n",
    "    \"\"\"Asymmetric exponential decay peak function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray\n",
    "        Independent variable.\n",
    "    center : int or float\n",
    "        The center of the peak.\n",
    "    amplitude : float\n",
    "        Amplitude parameter.\n",
    "    decay : float\n",
    "        Decay parameter.\n",
    "    skew : float\n",
    "        Skew parameter.\n",
    "    baseline : float\n",
    "        Baseline parameter.\n",
    "    floor : float\n",
    "        Minimum value that the result can take.\n",
    "    ceiling : float\n",
    "        Maximum value that the result can take.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : ndarray\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    decay_right = 2**(-skew) * decay\n",
    "    decay_left = 2**skew * decay\n",
    "\n",
    "    # locate the index at which to split data into left and right flanks\n",
    "    ix_split = bisect_right(x, center)\n",
    "\n",
    "    # compute left flank\n",
    "    xl = center - x[:ix_split]\n",
    "    yl = baseline + amplitude * np.exp(-xl / decay_left)\n",
    "\n",
    "    # compute right flank\n",
    "    xr = x[ix_split:] - center\n",
    "    yr = baseline + amplitude * np.exp(-xr / decay_right)\n",
    "\n",
    "    # prepare output\n",
    "    y = np.concatenate([yl, yr])\n",
    "\n",
    "    # apply limits\n",
    "    y = y.clip(floor, ceiling)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc59faa7-6e29-4387-aded-1c7dbf4cb283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## define function for modeling/ deteriming the guassian peak\n",
    "def gaussian_peak(x, center, amplitude, sigma, baseline, floor, ceiling):\n",
    "    \"\"\"Gaussian peak function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray\n",
    "        Independent variable.\n",
    "    center : int or float\n",
    "        The center of the peak.\n",
    "    amplitude : float\n",
    "        Amplitude parameter.\n",
    "    sigma : float\n",
    "        Width parameter.\n",
    "    baseline : float\n",
    "        Baseline parameter.\n",
    "    floor : float\n",
    "        Minimum value that the result can take.\n",
    "    ceiling : float\n",
    "        Maximum value that the result can take.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : ndarray\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    y = (baseline +\n",
    "         amplitude *\n",
    "         np.exp(-(x - center)**2 / (2 * sigma**2)))\n",
    "\n",
    "    # apply limits\n",
    "    y = y.clip(floor, ceiling)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5654fc88-f717-4d46-bd36-9a1bc1a4b3e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define function for determining asymetric guasian peak\n",
    "def skewed_gaussian_peak(x, center, amplitude, sigma, skew, baseline, floor, ceiling):\n",
    "    \"\"\"Asymmetric Gaussian peak function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray\n",
    "        Independent variable.\n",
    "    center : int or float\n",
    "        The center of the peak.\n",
    "    amplitude : float\n",
    "        Amplitude parameter.\n",
    "    sigma : float\n",
    "        Width parameter.\n",
    "    skew : float\n",
    "        Skew parameter.\n",
    "    baseline : float\n",
    "        Baseline parameter.\n",
    "    floor : float\n",
    "        Minimum value that the result can take.\n",
    "    ceiling : float\n",
    "        Maximum value that the result can take.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : ndarray\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    sigma_right = 2**(-skew) * sigma\n",
    "    sigma_left = 2**skew * sigma\n",
    "\n",
    "    # locate the index at which to split data into left and right flanks\n",
    "    ix_split = bisect_right(x, center)\n",
    "\n",
    "    # compute left flank\n",
    "    xl = center - x[:ix_split]\n",
    "    yl = (baseline +\n",
    "          amplitude *\n",
    "          np.exp(-xl**2 / (2 * sigma_left**2)))\n",
    "\n",
    "    # compute right flank\n",
    "    xr = x[ix_split:] - center\n",
    "    yr = (baseline +\n",
    "          amplitude *\n",
    "          np.exp(-xr**2 / (2 * sigma_right**2)))\n",
    "\n",
    "    # prepare output\n",
    "    y = np.concatenate([yl, yr])\n",
    "\n",
    "    # apply limits\n",
    "    y = y.clip(floor, ceiling)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab73cb32-96df-4f6f-92a1-28fd10ac2a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define funtion that fits skwed exponential peak to real world data/ my data\n",
    "def fit_exponential_peak(\n",
    "    ppos, \n",
    "    gpos, \n",
    "    stat_filtered, \n",
    "    gcenter, \n",
    "    gflank, \n",
    "    scan_interval,\n",
    "    init_amplitude,\n",
    "    min_amplitude,\n",
    "    max_amplitude,\n",
    "    init_decay,\n",
    "    min_decay,\n",
    "    init_skew,\n",
    "    min_skew,\n",
    "    max_skew,\n",
    "    init_baseline,\n",
    "    min_baseline,\n",
    "    max_baseline,\n",
    "    min_delta_aic,\n",
    "    min_stat_max,\n",
    "    debug=False,\n",
    "):\n",
    "\n",
    "    # locate region to fit\n",
    "    loc_region = slice(bisect_left(gpos, gcenter - gflank), \n",
    "                       bisect_right(gpos, gcenter + gflank))\n",
    "\n",
    "    # set up data to fit\n",
    "    x = gpos[loc_region]\n",
    "    y = stat_filtered[loc_region]\n",
    "\n",
    "    # fit peak model\n",
    "    peak_model = lmfit.Model(skewed_exponential_peak)\n",
    "    peak_params = lmfit.Parameters()\n",
    "    peak_params['center'] = lmfit.Parameter('center', vary=True, \n",
    "                                            value=gcenter, \n",
    "                                            min=gcenter - gflank, \n",
    "                                            max=gcenter + gflank)\n",
    "    peak_params['amplitude'] = lmfit.Parameter('amplitude', vary=True, \n",
    "                                               value=init_amplitude, \n",
    "                                               min=min_amplitude, \n",
    "                                               max=max_amplitude)\n",
    "    peak_params['decay'] = lmfit.Parameter('decay', \n",
    "                                           vary=True, \n",
    "                                           value=init_decay, \n",
    "                                           min=min_decay, \n",
    "                                           max=gflank/3)\n",
    "    peak_params['skew'] = lmfit.Parameter('skew', \n",
    "                                          vary=True, \n",
    "                                          value=init_skew, \n",
    "                                          min=min_skew, \n",
    "                                          max=max_skew)\n",
    "    peak_params['baseline'] = lmfit.Parameter('baseline', vary=True, \n",
    "                                              value=init_baseline, \n",
    "                                              min=min_baseline, \n",
    "                                              max=max_baseline)\n",
    "    peak_params['ceiling'] = lmfit.Parameter('ceiling', vary=False, value=1)\n",
    "    peak_params['floor'] = lmfit.Parameter('floor', vary=False, value=0)\n",
    "    peak_result = peak_model.fit(y, x=x, params=peak_params)\n",
    "\n",
    "    # fit null model\n",
    "    null_model = lmfit.models.ConstantModel()\n",
    "    null_params = lmfit.Parameters()\n",
    "    null_params['c'] = lmfit.Parameter('c', vary=True, value=init_baseline, min=0, max=1)\n",
    "    null_result = null_model.fit(y, x=x, params=null_params)\n",
    "\n",
    "    # compute fit\n",
    "    peak_delta_i = int(null_result.aic - peak_result.aic)\n",
    "\n",
    "    # determine if we want to emit a result - we will do this if delta_i is above threshold\n",
    "    # and also only if the fitted peak center is within the scan interval - if it is beyond, then \n",
    "    # we will get a better fit in a different scan interval\n",
    "    fit_gcenter = peak_result.params['center'].value\n",
    "\n",
    "    peak_in_scan_interval = ((gcenter - scan_interval) < fit_gcenter < (gcenter + scan_interval))\n",
    "    \n",
    "    fit_params = peak_result.params\n",
    "    fit_skew = fit_params['skew'].value\n",
    "    fit_decay = fit_params['decay'].value\n",
    "    decay_right = 2**(-fit_skew) * fit_decay\n",
    "    decay_left = 2**fit_skew * fit_decay\n",
    "    focus_gstart = fit_gcenter - .05 * decay_left\n",
    "    focus_gstop = fit_gcenter + .05 * decay_right\n",
    "    span1_gstart = fit_gcenter - 1*decay_left\n",
    "    span1_gstop = fit_gcenter + 1*decay_right\n",
    "    span2_gstart = fit_gcenter - 2*decay_left\n",
    "    span2_gstop = fit_gcenter + 2*decay_right\n",
    "\n",
    "    # Determine chromosome physical position.\n",
    "    fit_pcenter = af_g2p(contig, fit_gcenter)\n",
    "    focus_pstart = af_g2p(contig, focus_gstart)\n",
    "    focus_pstop = af_g2p(contig, focus_gstop)\n",
    "    span1_pstart = af_g2p(contig, span1_gstart)\n",
    "    span1_pstop = af_g2p(contig, span1_gstop)\n",
    "    span2_pstart = af_g2p(contig, span2_gstart)\n",
    "    span2_pstop = af_g2p(contig, span2_gstop)\n",
    "\n",
    "    # Determine max value, pos max value (genetic, physical).\n",
    "    loc_peak = slice(bisect_left(x, span2_gstart), \n",
    "                     bisect_right(x, span2_gstop))\n",
    "    if loc_peak.stop == loc_peak.start:\n",
    "        # In some rare cases, there are no data points within this\n",
    "        # peak region. This is probably pathological, so don't output\n",
    "        # a signal in this case.\n",
    "        return\n",
    "    x_peak = x[loc_peak]\n",
    "    y_peak = y[loc_peak]\n",
    "    loc_max = np.argmax(y_peak)\n",
    "    gpos_max = x_peak[loc_max]\n",
    "    ppos_max = af_g2p(contig, gpos_max)\n",
    "    stat_max = y_peak[loc_max]\n",
    "\n",
    "    if peak_delta_i > min_delta_aic and stat_max > min_stat_max and peak_in_scan_interval:\n",
    "\n",
    "        if debug:\n",
    "\n",
    "            x_fitted = np.linspace(x[0], x[-1], 1000)\n",
    "            y_fitted = skewed_exponential_peak(\n",
    "                x=x_fitted, \n",
    "                center=peak_result.params['center'].value, \n",
    "                amplitude=peak_result.params['amplitude'].value, \n",
    "                decay=peak_result.params['decay'].value, \n",
    "                skew=peak_result.params['skew'].value, \n",
    "                baseline=peak_result.params['baseline'].value, \n",
    "                floor=peak_result.params['floor'].value, \n",
    "                ceiling=peak_result.params['ceiling'].value,\n",
    "            )\n",
    "            delta_i = null_result.aic - peak_result.aic\n",
    "            fig, ax = plt.subplots(facecolor='w', figsize=(6, 4))\n",
    "            ax.plot(x, y, marker='o', linestyle=' ', mfc='none', markersize=2);\n",
    "            ax.plot(x_fitted, y_fitted, marker=None, linestyle='--', color='k');\n",
    "            ax.axvspan(fit_gcenter - decay_left, fit_gcenter + decay_right, zorder=0, color='red', alpha=.2)\n",
    "            ax.axvspan(fit_gcenter - 2*decay_left, fit_gcenter + 2*decay_right, zorder=0, color='red', alpha=.2)\n",
    "            ax.axvline(fit_gcenter, color='red', lw=2, zorder=0)\n",
    "            ax.axhline(min_stat_max, color='k', lw=1, linestyle='--', zorder=0)\n",
    "            ax.annotate(\n",
    "                f'$n={x.shape[0]}$\\n' + \n",
    "                f'$AIC={peak_result.aic:.0f}$\\n' +\n",
    "                f'$BIC={peak_result.bic:.0f}$\\n' +\n",
    "                f'$\\\\chi^{2}={peak_result.chisqr:.3f}$\\n' +\n",
    "                f'$\\\\Delta_{{i}}={delta_i:.0f}$\\n' + \n",
    "                f'$\\\\Delta_{{i}} / n = {delta_i/x.shape[0]:.2f}$\\n',\n",
    "                xy=(0, 1), xycoords='axes fraction',\n",
    "                xytext=(5, -5), textcoords='offset points',\n",
    "                va='top', ha='left', fontsize=8,\n",
    "            )\n",
    "            ax.set_xlim(gcenter - gflank, gcenter + gflank)\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.set_ylabel(\"H12\")\n",
    "            ax.set_xlabel(f\"Contig {contig} position (cM)\")\n",
    "            ax.set_title(f\"center {gcenter}, flank {gflank}\")\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "            print(peak_result.fit_report())\n",
    "\n",
    "        # build output record\n",
    "        record = dict(\n",
    "            cohort_id=cohort_id,\n",
    "            contig=contig,\n",
    "            gcenter=fit_gcenter,\n",
    "            pcenter=fit_pcenter,\n",
    "            delta_i=peak_delta_i,\n",
    "            stat_max=stat_max,\n",
    "            gpos_max=gpos_max,\n",
    "            ppos_max=ppos_max,\n",
    "            focus_gstart=focus_gstart,\n",
    "            focus_gstop=focus_gstop,\n",
    "            span1_gstart=span1_gstart,\n",
    "            span1_gstop=span1_gstop,\n",
    "            span2_gstart=span2_gstart,\n",
    "            span2_gstop=span2_gstop,\n",
    "            focus_pstart=focus_pstart,\n",
    "            focus_pstop=focus_pstop,\n",
    "            span1_pstart=span1_pstart,\n",
    "            span1_pstop=span1_pstop,\n",
    "            span2_pstart=span2_pstart,\n",
    "            span2_pstop=span2_pstop,\n",
    "            amplitude=fit_params['amplitude'].value,\n",
    "            decay=fit_decay,\n",
    "            skew=fit_skew,\n",
    "            decay_left=decay_left,\n",
    "            decay_right=decay_right,\n",
    "            baseline=fit_params['baseline'].value,\n",
    "            aic=peak_result.aic,\n",
    "            bic=peak_result.bic,\n",
    "            rss=peak_result.chisqr,\n",
    "            constant_aic=null_result.aic,\n",
    "            # params=fit_params,\n",
    "            # result=peak_result,\n",
    "        )\n",
    "\n",
    "        return record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c7fe6d-bbc2-4083-980c-0b7cd6c1cd0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## this function detects and corrects the filtred peaks\n",
    "\n",
    "@numba.njit\n",
    "def hampel_filter(x, size, t=3):\n",
    "    # https://link.springer.com/article/10.1186/s13634-016-0383-6\n",
    "    # https://towardsdatascience.com/outlier-detection-with-hampel-filter-85ddf523c73d\n",
    "    \n",
    "    y = x.copy()\n",
    "    mad_scale_factor = 1.4826\n",
    "    \n",
    "    for i in range(size, len(x) - size):\n",
    "        # window\n",
    "        w = x[i - size:i + size]\n",
    "        # window median\n",
    "        m = np.median(w)\n",
    "        # median absolute deviation\n",
    "        mad = np.median(np.abs(w - m))\n",
    "        # MAD scale estimate\n",
    "        s = mad_scale_factor * mad\n",
    "        # construct response\n",
    "        if np.abs(x[i] - m) > (t * s):\n",
    "            y[i] = m\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ef79718-76b4-446c-bb17-32193b01587d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## fxn runs the humple deeply/ continously until there are no outliers \n",
    "@numba.njit\n",
    "def recursive_hampel_filter(x, size, t=3):\n",
    "    # https://link.springer.com/article/10.1186/s13634-016-0383-6\n",
    "    # https://towardsdatascience.com/outlier-detection-with-hampel-filter-85ddf523c73d\n",
    "    \n",
    "    y = x.copy()\n",
    "    mad_scale_factor = 1.4826\n",
    "    \n",
    "    for i in range(size, len(x) - size):\n",
    "        # window\n",
    "        w = y[i - size:i + size]\n",
    "        # window median\n",
    "        m = np.median(w)\n",
    "        # median absolute deviation\n",
    "        mad = np.median(np.abs(w - m))\n",
    "        # MAD scale estimate\n",
    "        S = mad_scale_factor * mad\n",
    "        # construct response\n",
    "        if np.abs(y[i] - m) > (t * S):\n",
    "            y[i] = m\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6562572-2310-48af-8c62-348ce65ceee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## \n",
    "# define function that reads and returns a genetic map dataframe for the three contigues \n",
    "\n",
    "#def read_af_gmap(contig):\n",
    "    #if contig in {\"2RL\", \"3RL\"}:\n",
    "        #chrom = contig[0]\n",
    "        #contig_r, contig_l = f\"{chrom}R\", f\"{chrom}L\"\n",
    "        #df_r = read_af_gmap(contig_r)## run fxn recursively on R xsome \n",
    "       # df_l = read_af_gmap(contig_l)## as above for L \n",
    "        #max_ppos = df_r[\"pposition\"].iloc[-1]## retrive last/ least value of the ppposition column in df and assigns it to max_pos\n",
    "        #max_gpos = df_r[\"gposition\"].iloc[-1]## same as above for the genetic position\n",
    "        #df_l = df_l.iloc[1:]\n",
    "        #df_l[\"pposition\"] += max_ppos\n",
    "        #df_l[\"gposition\"] += max_gpos\n",
    "        #df = pd.concat([df_r, df_l], axis=0, ignore_index=True) \n",
    "    #elif contig == \"X\":\n",
    "        # Handling for the X chromosome\n",
    "        #gmap_dir = \"/home/namulil/lstm_projects/funestus_llineup/notebooks/Signal_localisation/Af_\"\n",
    "        #gmap_file_path = f\"{gmap_dir}{contig}.gmap\"\n",
    "        #df = pd.read_csv(gmap_file_path, sep=\"\\t\")\n",
    "    #else:\n",
    "        #gmap_dir= \"/home/namulil/lstm_projects/funestus_llineup/notebooks/Signal_localisation/Af_\"\n",
    "        #gmap_file_path = f\"{gmap_dir}{contig}.gmap\"\n",
    "        #df = pd.read_csv(gmap_file_path, sep=\"\\t\")\n",
    "    #return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb49807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_af_gmap(contig):\n",
    "    # Handle contigs labeled as \"X\"\n",
    "    if contig in {\"3RL\"}:\n",
    "        # Special handling for entire chromosome arms labeled as \"RL\" instead of split xsome from harun\n",
    "        gmap_dir = \"/home/namulil/lstm_projects/funestus_llineup/notebooks/Signal_localisation/af_/\"\n",
    "        gmap_file_path = f\"{gmap_dir}Af_{contig}.gmap\"\n",
    "\n",
    "        \n",
    "               \n",
    "        # Read the file directly\n",
    "        df = pd.read_csv(gmap_file_path, sep=\"\\t\")\n",
    "    else:\n",
    "        # Handle other chromosomes (if applicable)\n",
    "        gmap_dir = \"/home/namulil/lstm_projects/funestus_llineup/notebooks/Signal_localisation/af_/\"\n",
    "        gmap_file_path = f\"{gmap_dir}Af_{contig}.gmap\"\n",
    "        \n",
    "          \n",
    "        # Read the file\n",
    "        df = pd.read_csv(gmap_file_path, sep=\"\\t\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "864cb6ef-d07c-4e39-a06d-5e6b3e4b8200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=None)## catches the fxn's output\n",
    "def af_gmap(contig):\n",
    "    af1 = malariagen_data.Af1(pre = True)\n",
    "        \n",
    "    # read in the genetic map file\n",
    "    df_gmap = read_af_gmap(contig)## call previois fxn to retrieve gmaps data for a specific contig as a datafram\n",
    "\n",
    "    # set up an array of per-base recombination rate values\n",
    "    rr = np.zeros(len(af1.genome_sequence(contig)), dtype=\"f8\")## NOT SURE WHY ARRAY IS OF ZEROS THO!\n",
    "\n",
    "    # fill in the recombination rate values from the genetic map file\n",
    "    for row, next_row in zip(\n",
    "        itertools.islice(df_gmap.itertuples(), 0, len(df_gmap)-1), \n",
    "        itertools.islice(df_gmap.itertuples(), 1, None)):\n",
    "        \n",
    "        # N.B., the genetic map file is in units of cM / Mbp\n",
    "        # we multiple by 1e-6 to convert to cM / bp\n",
    "        rr[row.position-1:next_row.position] = row.rrate * 1e-6\n",
    "    \n",
    "    # compute mapping from physical to genetic position\n",
    "    gmap = np.cumsum(rr)## map physical position (bps) to genetic positions (cM)\n",
    "        \n",
    "    return gmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "735e1a42-95a0-4e73-aebc-27874fb13417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def af_p2g(contig, ppos):\n",
    "    \"\"\"Convert physical position (bp) to genetic position (cM).\"\"\"\n",
    "    gmap = af_gmap(contig) ## fetch the genetic mapfor a given contig\n",
    "    gpos = gmap[ppos - 1]## use the 0-based index to access the genetic position\n",
    "    return gpos## return corresponding genetic position\n",
    "\n",
    "\n",
    "def af_g2p(contig, gpos):\n",
    "    gmap = af_gmap(contig)\n",
    "    ppos = bisect_left(gmap, gpos) + 1\n",
    "    return ppos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815b034f-28fe-44f1-b40d-e3e119a63e75",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9cd5e-a195-4a25-a2a5-d521fb4f1d39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ag_p2g(\"2RL\", 10_000_000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
